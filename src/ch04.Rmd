---
title: "Chapter 4"
author: "Matt Emery"
date: "October 22, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(rethinking)
library(tidyverse)
```

**4E1.** In the model definition below, which line is the likelihood?

$$y_i ∼ Normal(μ, σ)$$
$$μ ∼ Normal(0, 10)$$

$$σ ∼ Uniform(0, 10)$$
$y_i ∼Normal(\mu, \sigma)$ is the likelihood.

**4E2.** In the model definition just above, how many parameters are in the posterior distribution?

There are two paramaters in the posterior distribution: $\mu$ and $\sigma$.

**4E3.** Using the model definition above, write down the appropriate form of Bayes’ theorem that
includes the proper likelihood and priors.

$$p(\mu,\sigma|y) = \frac{N(y|\mu,\sigma)N(\mu|0, 10)Unif(\sigma|0,10)}{\int\int\ N(y|\mu,\sigma)N(\mu|0, 10)Unif(\sigma|0,10)d\mu d\sigma}$$

**4E4.** In the model definition below, which line is the linear model?
$$y_i ∼ Normal(μ, σ)$$
$$μ_i = α + βx_i$$
$$ α ∼ Normal(0, 10)$$
$$β ∼ Normal(0, 1)$$
$$σ ∼ Uniform(0, 10)$$
Answer: $μ_i = α + βx_i$

**4E5.** In the model definition just above, how many parameters are in the posterior distribution?

Three: $\alpha$, $\beta$ and $\sigma$

## Medium.

**4M1.** For the model definition below, simulate observed heights from the prior (not the posterior).

$$y_i ∼ Normal(μ, σ)$$
$$μ ∼ Normal(0, 10)$$
$$σ ∼ Uniform(0, 10)$$

```{r}
prior <- rnorm(1000, rnorm(1000, 0, 10), runif(1000, 0, 10))
sample(prior, 100)
```

**4M2.** Translate the model just above into a map formula.

```{r}
alist(
  y ~ dnorm(mu, sigma),
  mu ~ dnorm(0, 10),
  sigma ~ dunif(0, 10)
)
```


**4M3.** Translate the map model formula below into a mathematical model definition.

```{r}
flist <- alist(
  y ~ dnorm( mu , sigma ),
  mu <- a + b*x,
  a ~ dnorm( 0 , 50 ),
  b ~ dunif( 0 , 10 ),
  sigma ~ dunif( 0 , 50 )
)
```

$$
\begin{eqnarray}
  y_i \sim N(\mu, \sigma) \\
  \mu = a + bx_i \\
  a \sim N(0, 50) \\
  b \sim Unif(0, 10) \\
  \sigma \sim Unif(0, 50)
\end{eqnarray}
$$

**4M4.** A sample of students is measured for height each year for 3 years. After the third year, you want
to fit a linear regression predicting height using year as a predictor. Write down the mathematical
model definition for this regression, using any variable names and priors you choose. Be prepared to
defend your choice of priors.

$$
\begin{aligned}
  y_i \sim N(\mu, \sigma) \\
  \mu = a + bx_i \\
  a \sim N(140, 15) \\
  b \sim Unif(0, 30) \\
  \sigma \sim Unif(0, 50)
\end{aligned}
$$

**4M5.** Now suppose I tell you that the average height in the first year was 120 cm and that every
student got taller each year. Does this information lead you to change your choice of priors? How?

Assuming that the first year means that $x_i = 1$, then my new prior would be: 
$$a \sim N(105, 15)$$
This is 120 - the center of the uniform distribution. $b$ doesn't change because I already accounted for non-negative growth.

**NOTE**: The answer guide seems to suggest that nothing should be changed because the data is now influencing the prior.

**4M6.** Now suppose I tell you that the variance among heights for students of the same age is never
more than 64cm. How does this lead you to revise your priors?

With the same note as before, I would recommend changing the prior to:

$$\sigma \sim Unif(0, 64)$$

## Hard

**4H1.** The weights listed below were recorded in the !Kung census, but heights were not recorded for
these individuals. Provide predicted heights and 89% intervals (either HPDI or PI) for each of these
individuals. That is, fill in the table below, using model-based predictions.

| Individual | weight | expected height | 89% interval |
|------------|--------|-----------------|--------------|
| 1          | 46.95  |                 |              |
| 2          | 43.72  |                 |              |
| 3          | 64.78  |                 |              |
| 4          | 32.59  |                 |              |
| 5          | 54.63  |                 |              |

```{r}
data(Howell1)
```

```{r}
kung_height_model <- alist(
  height ~ dnorm( mu , sigma ),
  mu <- a + b*weight,
  a ~ dnorm( 0 , 50 ),
  b ~ dunif( 0 , 10 ),
  sigma ~ dunif( 0 , 50 )
)
```

```{r}
fitted_kung_model <- rethinking::map(kung_height_model, data = Howell1)
```

```{r}
kung_predictions <- link(fitted_kung_model, list(weight = c(46.95, 43.72, 64.78, 32.59, 54.63)))
```
```{r}
expected_heights <- as_tibble(kung_predictions) %>% 
  summarise_all(mean) %>% 
  t() %>% 
  as.numeric()

expected_heights
```

```{r}
interval_89 <- as_tibble(kung_predictions) %>% 
  summarise_all(~ paste(round(HPDI(.)[[1]],2), "-", round(HPDI(.)[[2]], 2))) %>% 
  t() %>% 
  as.character()

interval_89
```


```{r}
data_frame(Individual = seq(1, 5),
           Weight = c(46.95, 43.72, 64.78, 32.59, 54.63),
           `Expected Heights` = expected_heights,
           `89% Interval` = interval_89)
```

Errors: 
- Didn't remove < 18 Ages.
- Calculated predictive intervals, not confidence intervals

```{r}
howell_adults <- Howell1 %>% 
  filter(age >= 18)
```

```{r}
fitted_kung_model <- rethinking::map(kung_height_model, data = howell_adults)
kung_predictions <- link(fitted_kung_model, list(weight = c(46.95, 43.72, 64.78, 32.59, 54.63)))

expected_heights <- as_tibble(kung_predictions) %>% 
  summarise_all(mean) %>% 
  t() %>% 
  as.numeric()
```

```{r}
kung_simulations <- rethinking::sim(fitted_kung_model, data = list(weight = c(46.95, 43.72, 64.78, 32.59, 54.63)))
head(kung_simulations)
```


```{r}
interval_89 <- as_tibble(kung_simulations) %>% 
  summarise_all(~ paste(round(HPDI(.)[[1]],2), "-", round(HPDI(.)[[2]], 2))) %>% 
  t() %>% 
  as.character()

data_frame(Individual = seq(1, 5),
           Weight = c(46.95, 43.72, 64.78, 32.59, 54.63),
           `Expected Heights` = expected_heights,
           `89% Interval` = interval_89)
```


**4H2.** Select out all the rows in the Howell1 data with ages below 18 years of age. If you do it right,
you should end up with a new data frame with 192 rows in it.
(a) Fit a linear regression to these data, using map . Present and interpret the estimates. For every
10 units of increase in weight, how much taller does the model predict a child gets?
(b) Plot the raw data, with height on the vertical axis and weight on the horizontal axis. Super-
impose the MAP regression line and 89% HPDI for the mean. Also superimpose the 89% HPDI for
predicted heights.
(c) What aspects of the model fit concern you? Describe the kinds of assumptions you would
change, if any, to improve the model. You don’t have to write any new code. Just explain what the
model appears to be doing a bad job of, and what you hypothesize would be a better model.

**4H3.** Suppose a colleague of yours, who works on allometry, glances at the practice problems just
above. Your colleague exclaims, “That’s silly. Everyone knows that it’s only the logarithm of body
weight that scales with height!” Let’s take your colleague’s advice and see what happens.
(a) Model the relationship between height (cm) and the natural logarithm of weight (log-kg). Use
the entire Howell1 data frame, all 544 rows, adults and non-adults. Fit this model, using quadratic
approximation:


$$
\begin{aligned}
h_i ∼ Normal(μ_i , σ)\\
μ_i = α + β log(w_i )\\
α ∼ Normal(178, 100)\\
β ∼ Normal(0, 100)\\
σ ∼ Uniform(0, 50)\\
\end{aligned}
$$

where $h_i$ is the height of individual i and $w_i$ is the weight (in kg) of individual i. The function for
computing a natural log in R is just log . Can you interpret the resulting estimates?

(b) Begin with this plot:

```{r}
plot( height ~ weight , data = Howell1 ,
col = col.alpha(rangi2,0.4) )
```

Then use samples from the quadratic approximate posterior of the model in (a) to superimpose on
the plot: (1) the predicted mean height as a function of weight, (2) the 97% HPDI for the mean, and
(3) the 97% HPDI for predicted heights.

